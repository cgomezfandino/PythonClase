{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick scraping example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we deal with a basic scraping example using <code>lxml</code>. Note there are other libraries that could be useful for the same purpose as <a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup</a>. \n",
    "For a more systematic approach to scraping, <a href=\"http://scrapy.org/\">Scrapy</a> is a good solution. If you need to interact with HTML pages, <a href=\"\">Selenium</a> is the best solution. However, Scrapy and Selenium are advanced tools and require deep knowledge of HTML and Javascript, together with an understanding of advanced architectural concepts. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: Anaconda does not install css selector libraries by default. You may need to install them:\n",
    "pip install cssselect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step one: select and look at the markup of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping basically consists of getting a Web page and processing its HTML content to extract some information and save or convert that information in other format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take as example the page with the ranking of companies of Forbes: http://www.forbes.com/global2000/list/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we neeed to do is to look at the markup of the page. You can do it by using in Firefox:\n",
    "* Tools > Web Developer > Page Source \n",
    "\n",
    "But it is better to use some more advanced view of the code. In Firefox, you can use:\n",
    "* Tools > Web Developer > Inspector.\n",
    "\n",
    "Or use some addon like Firebug: https://addons.mozilla.org/es/firefox/addon/firebug/\n",
    "The good thing of Firebug is that it allows you to get from the page directly XPath expressions (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Web page selected, we can see that the list of products and prices are inside a <code>tbody</code> element that contains a number of elements with class <code>company</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case we can get titles and prices based on CSS classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step one: get the Web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply retrieving the text of the page. We can do it with the <code>request</code> module or with any other one with a similar purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://www.forbes.com/global2000/list/\"\n",
    "page = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step three: parse the Web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "Entity 'rsquo' not defined, line 10, column 182",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Entity 'rsquo' not defined, line 10, column 182\n"
     ]
    }
   ],
   "source": [
    "from lxml import html, etree\n",
    "utf8_parser = etree.XMLParser(encoding='utf-8')\n",
    "s = page.text.encode('utf-8')\n",
    "tree = etree.fromstring(s, parser=utf8_parser)\n",
    "tree = html.parse(page.text.encode('utf-8'))\n",
    "# error... not well formed.\n",
    "# take the fragment from disk instead...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have in <code>tree</code> a representation of the contents of the page. Now we have to options to extract the data, using CSS selectors or XPath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"forbes-fragment.html\")\n",
    "tree = html.document_fromstring(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step four: get the data with CSS selectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take advantage of our knowledge that titles and prices are with particular CSS selectors or XPath... Using the CSS selector syntax: http://www.w3.org/TR/CSS2/selector.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "<type 'list'>\n",
      "<class 'lxml.html.HtmlElement'>\n"
     ]
    }
   ],
   "source": [
    "#companies = tree.cssselect('tr')\n",
    "companies = tree.xpath('//tr[@class=\"data\"]') # xpath expresiones declarativas que permite seleccionar una parte del documento html\n",
    "##// todo los elementos tr, y me filtres todos las clases de \"data\"\n",
    "\n",
    "print len(companies)\n",
    "print type(companies)\n",
    "print type(companies[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate each element and get the subelements in each of the company td tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = []\n",
    "# Note we are excluding the header starting in 1. \n",
    "for i in range(1, len(companies)):\n",
    "    # There are seven <td> elements:\n",
    "    cells = companies[i].getchildren()\n",
    "    name = cells[2].xpath(\"a/text()\")[0]\n",
    "    country = cells[3].text\n",
    "    value = cells[7].text\n",
    "    L.append([name, country, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['China Construction Bank', 'China', '$212.9 B'],\n",
       " ['Agricultural Bank of China', 'China', '$189.9 B'],\n",
       " ['Bank of China', 'China', '$199.1 B'],\n",
       " ['Berkshire Hathaway', 'United States', '$354.8 B'],\n",
       " ['JPMorgan Chase', 'United States', '$225.5 B']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can do something similar with <a href=\"http://www.w3schools.com/xpath/\">XPath</a> expressions (you can get the XPath of an element in a Web page with Firebug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: transform the data (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the value follows the format: \"$174.4 B\". We need to extract the number from that string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['China Construction Bank', 'China', 212.9], ['Agricultural Bank of China', 'China', 189.9], ['Bank of China', 'China', 199.1], ['Berkshire Hathaway', 'United States', 354.8], ['JPMorgan Chase', 'United States', 225.5]]\n",
      "<type 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Easiest way is cutting the dollar and billion signs:\n",
    "for i in range(len(L)):\n",
    "    label = L[i][2]\n",
    "    L[i][2] = float(label[1:-1])\n",
    "print L[:5]\n",
    "print type(L[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Move it to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China Construction Bank</td>\n",
       "      <td>China</td>\n",
       "      <td>212.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agricultural Bank of China</td>\n",
       "      <td>China</td>\n",
       "      <td>189.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bank of China</td>\n",
       "      <td>China</td>\n",
       "      <td>199.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>United States</td>\n",
       "      <td>354.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPMorgan Chase</td>\n",
       "      <td>United States</td>\n",
       "      <td>225.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>United States</td>\n",
       "      <td>357.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company        country  value\n",
       "0     China Construction Bank          China  212.9\n",
       "1  Agricultural Bank of China          China  189.9\n",
       "2               Bank of China          China  199.1\n",
       "3          Berkshire Hathaway  United States  354.8\n",
       "4              JPMorgan Chase  United States  225.5\n",
       "5                 Exxon Mobil  United States  357.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(L, columns = [\"company\", \"country\", \"value\"])\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ff1d8400a853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# habria que instalar html5lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhtml5lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://en.wikipedia.org/wiki/Breguet_14'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#for df in dfs:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\cgome\\Anaconda2\\lib\\site-packages\\pandas\\io\\html.pyc\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, tupleize_cols, thousands, encoding)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0m_validate_header_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m     return _parse(flavor, io, match, header, index_col, skiprows,\n\u001b[0;32m--> 874\u001b[0;31m                   parse_dates, tupleize_cols, thousands, attrs, encoding)\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\cgome\\Anaconda2\\lib\\site-packages\\pandas\\io\\html.pyc\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, header, index_col, skiprows, parse_dates, tupleize_cols, thousands, attrs, encoding)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0mretained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\cgome\\Anaconda2\\lib\\site-packages\\pandas\\io\\html.pyc\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflavor\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'bs4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_HTML5LIB\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"html5lib not found, please install it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_BS4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             raise ImportError(\n",
      "\u001b[0;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "# habria que instalar html5lib \n",
    "import html5lib\n",
    "dfs = pd.read_html('https://en.wikipedia.org/wiki/Breguet_14')\n",
    "dfs\n",
    "#for df in dfs:\n",
    " #   print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
